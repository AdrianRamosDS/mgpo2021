{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling Methods\n",
    "\n",
    "<img style=\"float: right; margin: 0px 0px 15px 15px;\" src=\"https://upload.wikimedia.org/wikipedia/commons/b/bf/Simple_random_sampling.PNG\" width=\"400px\" height=\"400px\" />\n",
    "\n",
    "> We now have a suite of methods for **exact** inference. Although these methods exploit the graphical structure of our networks, they are not efficient (in the general case) in the sense that the time they need to obtain the result is exponential in the size of the problem.\n",
    ">\n",
    "> Therefore, we will study sampling methods to achieve approximate inference in graphical models.\n",
    "\n",
    "> **Objetives:**\n",
    "> - To remember how to estimate statistics using samples.\n",
    "> - To study a simple sampling method for Bayesian networks.\n",
    "> - To describe the Markov Chain Monte Carlo methods.\n",
    "\n",
    "> **References:**\n",
    "> - Probabilistic Graphical Models: Principles and Techniques, By Daphne Koller and Nir Friedman. Ch. 12.\n",
    "> - Mastering Probabilistic Graphical Models Using Python, By Ankur Ankan and Abinash Panda. Ch. 4.\n",
    "> - Probabilistic Graphical Models Specialization, offered through Coursera. Prof. Daphne Koller.\n",
    "\n",
    "\n",
    "<p style=\"text-align:right;\"> Imagen recuperada de: https://upload.wikimedia.org/wikipedia/commons/b/bf/Simple_random_sampling.PNG.</p>\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Sampling in Bayesian Networks\n",
    "\n",
    "First, let's remember how we estimate simple things using samples from a distribution $P$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Simple sampling\n",
    "\n",
    "Let $\\mathcal{D}=\\{x_1, x_2, \\dots, x_M\\}$ be a dataset of **independent and identically distributed (IID)** samples from the distribution $P(X=x)$.\n",
    "\n",
    "For example, if $X$ is a binary random variable ($\\mathrm{Val}(X)=\\{x^0, x^1\\}$) and $P(X=x^1)=p$, then an estimator for $p$ is:\n",
    "\n",
    "$$\\hat{p} = \\frac{1}{M} \\sum_{i=1}^{M} I(x_i = x^1).$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# np.random.choice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample the binary distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimation of p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More generally, for any distribution $P$ and function $f$,\n",
    "\n",
    "$$E_P[f] \\approx \\frac{1}{M} \\sum_{i=1}^{M}f(x_i).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Application of this simple concept:**\n",
    "\n",
    "- [Montecarlo integration](https://en.wikipedia.org/wiki/Monte_Carlo_integration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How can we sample from a multinomial discrete distribution?\n",
    "\n",
    "Let $X$ be a discrete random variable with $\\mathrm{Val}(X)=\\{x^1, x^2, \\dots, x^k\\}$, and $P(x^i) = \\theta^i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually we have a pseudorandom number generator from the uniform distribution $\\mathcal{U}[0, 1]$ (equal probability of drawing any number between 0 and 1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy.random.rand\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we can sample as shown in the following image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='figures/discrete_sampling.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What theoretical guarantees do we have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Theorem (Hoeffding bound).* For the estimator $\\hat{p} = \\frac{1}{M} \\sum_{i=1}^{M} I(x_i = x^1)$, the inequality\n",
    "> \n",
    "> $$P_{\\mathcal{D}}(\\hat{p}\\notin[p-\\epsilon, p+\\epsilon]) \\leq 2 e^{-2 M \\epsilon^2}$$\n",
    ">\n",
    "> holds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Theorem (Chernoff bound).* For the estimator $\\hat{p} = \\frac{1}{M} \\sum_{i=1}^{M} I(x_i = x^1)$, the inequality\n",
    "> \n",
    "> $$P_{\\mathcal{D}}(\\hat{p}\\notin[p(1-\\epsilon), p(1+\\epsilon)]) \\leq 2 e^{- M p \\epsilon^2 / 3}$$\n",
    ">\n",
    "> holds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comments:**\n",
    "\n",
    "1. Hoeffding: additive error\n",
    "2. Chernoff: multiplicative errror\n",
    "3. Both say that \"the probability of a bad sample set (with error $\\epsilon$)\" is a decreasing function of the number of samples.\n",
    "4. These guarantees are extended for estimation over general functions.\n",
    "5. Issues appear when $p$ (the true value is small): $\\epsilon$ needs to be small relative to $p$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.**\n",
    "\n",
    "Assume that we want to be at least $1-\\delta$ confident that we will have a good estimator. How many samples do we need?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Forward sampling in Bayesian networks\n",
    "\n",
    "There are several ways to perform sampling over a Bayesian network. The *forward sampling* is perhaps the easiest and practical way to do it, since it is done in the natural calusal direction of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider the student example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='figures/Student1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sampling is done in the topological order:\n",
    "\n",
    "1. We begin with the nodes that don't have parents ($D,I$):\n",
    "   - $d^0, i^1$.\n",
    "\n",
    "2. Once the parents of a node have been sampled, we can sample that node using the corresponding row of the conditional distribution ($C,E$ using the rows corresponding to $i^1, d^0$):\n",
    "   - $c^0, e^0$.\n",
    "   - $r^1$\n",
    "\n",
    "3. Finally, the complete sample is $d^0, i^1, c^0, e^0, r^1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do we estimate probabilities using these samples?\n",
    "\n",
    "1. Goal: To estimate $P(\\bar{Y}=\\bar{y})$ (or a function of $\\bar{Y}$).\n",
    "\n",
    "   - Generate and collect samples from the Bayesian network. How many? \n",
    "   - Count the number of times that $\\bar{Y}=\\bar{y}$ and compute its relative frequency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What if we have evidence?\n",
    "\n",
    "2. Goal: To estimate $P(\\bar{Y}=\\bar{y} | \\bar{E}=\\bar{e})$.\n",
    "\n",
    "   - Rejection sampling algorithm:\n",
    "     - Generate samples from the Bayesian network.\n",
    "     - Throw away all those where $\\bar{E} \\neq \\bar{e}$\n",
    "     - Count the number of times that $\\bar{Y}=\\bar{y}$ and compute its relative frequency.\n",
    "     \n",
    "   - Expected fraction of samples kept after throwing away those that are not consistent with the evidence: $P(\\bar{e})$.\n",
    "   - Thus, we should generate: $M\\geq \\frac{\\log(2/\\delta)}{2P(\\bar{e})\\epsilon^2}$ samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The number of samples grows exponentially with the number of observed variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How is this done with `pgmpy`?\n",
    "\n",
    "First, let's compute the exact inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pgmpy.factors.discrete.TabularCPD\n",
    "\n",
    "# Import pgmpy.models.BayesianModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the model structure. We can define the network by just passing a list of edges.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining individual CPDs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associating the CPDs with the network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the marginal probability $P(C)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pgmpy.inference.VariableElimination\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see what we get using forward sampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pgmpy.sampling.BayesianModelSampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a sampling object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of samples for error of 1% and confidence of 99%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimation of P(C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, this method cannot be extended to Markov networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Markov Chain Monte Carlo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Markov Chain Monte Carlo (MCMC) methods appear as an answer to the above issue. These methods allow us to design an iterative sampling process that converges to the desired target distribution, which may be intractable to sample from directly.\n",
    "\n",
    "Let's remember what the Markov chains are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Markov chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that a **Markov chain** defines a probabilistic transition model $T(x \\to x')$ over some states $x$:\n",
    "\n",
    "$$\\forall x: \\sum_{x'}T(x \\to x') = 1.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:** Drunk man Markov chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"figures/drunkMC.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does the probability of being in a given state evolve?\n",
    "\n",
    "Given some initial probability distribution $P^{(0)}(X^{(0)})$, we can find $P^{(t)}(X^{(t)})$ as:\n",
    "\n",
    "$$P^{(t+1)}(X^{(t+1)} = x') = \\sum_{x} P^{(t)}(X^{(t)}) T(x \\to x').$$\n",
    "\n",
    "For example, we know that the drunk man begins his journey at $X=0$. Then:\n",
    "\n",
    "| $P^{(t)}$ | $-2$     | $-1$   | $0$     | $1$   | $2$      |\n",
    "| --------- | -------- | ------ | ------- | ----- | -------- |\n",
    "| $P^{(0)}$ | $0$      | $0$    | $1$     | $0$   | $0$      |\n",
    "| $P^{(1)}$ | $0$      | $0.25$ | $0.5$   | $0.25$| $0$      |\n",
    "| $P^{(2)}$ | $0.0625$ | $0.25$ | $0.375$ | $0.25$| $0.0625$ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transition matrix\n",
    "\n",
    "# Initial distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution 1, 2, ..., 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution 1000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After some iterations, the distribution converges to an stationary distribution.\n",
    "\n",
    "What happens if the initial distribution is changed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different P0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different P0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the stationary distribution satisfies:\n",
    "\n",
    "$$\\Pi(x') = \\sum_{x} \\Pi(x) T(x \\to x'),$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\\sum_{x} \\Pi(x) = 1,$$\n",
    "\n",
    "which forms a system of linear equations.\n",
    "\n",
    "For the above example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify and augment matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Least squares solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, **not all Markov chains converge to a unique distribution regardless the initial probability distribution**.\n",
    "\n",
    "> *Definition (Regular Markov chain).* A Markov chain is **regular** if there exists $k\\in\\mathbb{N}$ such that, for every $x, x' \\in \\mathrm{Val}(X)$, the probability of getting from $x$ to $x'$ in exactly $k$ steps is *positive* ($>0$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Theorem.* A regular Markov chain converges to a unique stationary distribution regardless the initial distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sufficient condition for regularity:**\n",
    "- Every two states $x, x'$ are connected with a path of positive probability.\n",
    "- For every state, there is a self-transition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Using a Markov chain\n",
    "\n",
    "Now that we know what a Markov chain is, let's examine how to use it in the context of approximate inference using sampling.\n",
    "\n",
    "- Goal: Compute $P(x \\in \\mathcal{S})$.\n",
    "  - But $P$ is too hard to sample from directly.\n",
    "  \n",
    "- Construct a Markov chain whose unique stationary distribution is $P$.\n",
    "\n",
    "- Sample $x^{(0)}$ from $P^{(0)}$.\n",
    "\n",
    "- For $t=0, 1, 2, \\dots$:\n",
    "  - Generate $x^{(t+1)}$ from $T(x^{(t)} \\to x')$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which samples will we use?\n",
    "\n",
    "We only want to use samples that are sampled form a distribution which is close to $P$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, at early iterations, $P^{(t)}$ is usually far from $P$.\n",
    "\n",
    "We should start collecting samples only after the chain has run long enough to **mix**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do you know if a chain has mixed or not?\n",
    "\n",
    "In general, it is very difficult to prove that a chain has mixed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many cases, you can prove that it has not:\n",
    "\n",
    " - Compare chain statistics in different windows within a single run of the chain;\n",
    " - and accross different runs initialized differently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the samples\n",
    "\n",
    "Once the chain mixes, all samples $x^{(t)}$ are from the stationary distribution $\\Pi$:\n",
    "\n",
    " - So we should use all $x^{(t)}$ for $t>T_{mix}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nearby samples are correlated (not IID)!\n",
    " - We shouldn't overestimate the quality of our estimator by simple counting the number of samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm\n",
    "\n",
    "1. For $c=1,\\dots,C$:\n",
    "   - Sample $x^{(c,0)}$ from $P^{(0)}$.\n",
    "   \n",
    "2. Repeat until mixing:\n",
    "   - For $c=1,\\dots,C$:\n",
    "     - Generate $x^{(c,t+1)}$ from $T(x^{(c,t)} \\to x')$.\n",
    "     - Compare window statistics in different chains to determine mixing.\n",
    "\n",
    "3. Repeat until sufficient samples:\n",
    "   - $\\mathcal{D} = \\emptyset$.\n",
    "   - For $c=1,\\dots,C$:\n",
    "     - Generate $x^{(c,t+1)}$ from $T(x^{(c,t)} \\to x')$.\n",
    "     - $\\mathcal{D} = \\mathcal{D} \\cup \\{x^{(c,t+1)}\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pros:**\n",
    "- General purpose.\n",
    "- Easy to implement.\n",
    "- Good theoretical guarantees as $t\\to\\infty$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cons:**\n",
    "- Lots of design choices.\n",
    "- Can be very slow to converge.\n",
    "- Difficult to tell whether it is working."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Gibbs sampling\n",
    "\n",
    "Until now we have the general framework clear. However, we still do not know how to construct a Markov chain with a desired unique stationary distribution.\n",
    "\n",
    "One simple way to do this is using the Gibbs chain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Target distribution $P_{\\Phi}(X_1, \\dots, X_n)$.\n",
    "- Markov chain state space: complete assinment $\\bar{x}$ to $\\bar{X} = \\{X_1, \\dots, X_n\\}$.\n",
    "- Transition model given an starting state $\\bar{x}^{(0)}$:\n",
    "  - For $i=1,\\dots,n$:\n",
    "    - Sample $x_i \\sim P_{\\Phi}(X_i | \\bar{x}_{-i})$; where $\\bar{x}_{-i}$ is an assignment to  $\\bar{X} = \\{X_1, \\dots, X_n\\}$, except for $X_i$.\n",
    "  - Set $\\bar{x}^{(t+1)} = \\bar{x}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"figures/Student1.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume that we want to sample the distribution $P_{\\Phi}(D, I, C | p^1, r^0)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting sample: $d^0, i^0, c^1$.\n",
    "\n",
    "| Sample          | Distribution to sample from   |\n",
    "| --------------- | ----------------------------- |\n",
    "| $d^0, i^0, c^1$ | $P(D|i^0, c^1, p^1, r^0)$     |\n",
    "| $d^1, i^0, c^1$ | $P(I|d^1, c^1, p^1, r^0)$     |\n",
    "| $d^1, i^1, c^1$ | $P(C|d^1, i^1, p^1, r^0)$     |\n",
    "| $d^1, i^1, c^1$ | This is $x^{(1)}$             |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pgmpy.sampling.GibbsSampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a sampling object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate N samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use rolling to get statistics on windows of predefined size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<script>\n",
    "  $(document).ready(function(){\n",
    "    $('div.prompt').hide();\n",
    "    $('div.back-to-top').hide();\n",
    "    $('nav#menubar').hide();\n",
    "    $('.breadcrumb').hide();\n",
    "    $('.hidden-print').hide();\n",
    "  });\n",
    "</script>\n",
    "\n",
    "<footer id=\"attribution\" style=\"float:right; color:#808080; background:#fff;\">\n",
    "Created with Jupyter by Esteban Jiménez Rodríguez.\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
